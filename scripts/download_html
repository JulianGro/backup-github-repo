#!/usr/bin/env zsh
set -eu

repo=$(git remote -v | grep origin | grep fetch | awk '{printf $2}' | sed 's|^.*:||' | sed 's|//github.com/||' | sed 's|\.git$||')
echo "repo: $repo"
last_id=$(jd ./issues/data.json ._keys._last)
echo "issues: $last_id"
mkdir -p ./issues/html/assets
cd ./issues/html

echo "Download issues HTML sequentially"
# See curl(1) and https://www.chronicle.com/blogs/profhacker/download-a-sequential-range-of-urls-with-curl/41055
curl -L "https://github.com/${repo}/issues/[1-${last_id}]" -o "#1.html" -# --limit-rate 10M

echo "Padding filenames with zeros"
for i in {1..$last_id}
do
  padded_id=$(printf %04d $i)
  mv "${i}.html" "${padded_id}.html"
done

replace_url_by_asset_hash(){
  url="$1"
  hash=$(echo $url | sha1sum | awk '{printf $1}')
  [ -e "./assets/${hash}" ] || {
    curl -sL "$url" > "./assets/${hash}" || { echo "couldn't fetch $url and put it into ./assets/${hash}" && exit 1 }
    sed -i "s@${url}@assets/${hash}\" data-original-url=\"${url}@g" *.html
  }
}

echo "Download stylesheets"
# cf https://stackoverflow.com/a/16318005/3324977
cat 0001.html | grep '<link' | grep 'rel="stylesheet"' | sed 's/.*href="//' | sed 's/".*//' | while read -r line ;
  do replace_url_by_asset_hash "$line" ;
done ;

# Preventing resources to be blocked by integrity checks
sed -i 's/ integrity=/ data-integrity=/' *.html

# Hidding some divs
sed -i 's/ class="signup-prompt-bg/ style="display: none;" class="hidden signup-prompt-bg/' *.html
sed -i 's/ class="flash flash-warn/ style="display: none;" class="hidden flash flash-warn/' *.html

urls=$(cat *.html | grep '<img' | grep -v data-original-url | sed 's/.*src="//' | sed 's/".*//' | grep -e '\w' | uniq)
urls_count=$(echo "$urls" | wc -l)

echo "Download images"
counter=0
echo "$urls" | while read -r line ; do
  echo "replacing: $line"
  replace_url_by_asset_hash "$line"
  counter=$((counter+1))
  printf "\rreplaced images: ${counter}/${urls_count}    "
done ;

echo "\ndone"
